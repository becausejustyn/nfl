---
title: "R Notebook"
output: html_notebook
---


## Estimating Run/Pass Tendencies with tidyModels and nflfastR

$$y_{it} \sim Bernoulli(p_{it})$$

$$logit(p_{it}) = \alpha + \gamma_{t} + \beta_{1}\hat{p}_i + \boldsymbol\beta\textbf{X}_{i}$$


where $y_{it}$ is going to be whether team $t$ called a pass on play $i$, $\gamma_{t}$ is a team effect which will be our measure of team strategy, and $\boldsymbol\beta\textbf{X}_{i}$ is going to be any other information we want to include such as quarterback ability, quality of defense, weather, or anything else of interest. $\hat{p}_i$ is the probability of a QB dropback that we'll generate with our model below. In effect, this will give us an expectation from which we'll measure deviances at the team level.


This is a classification problem where we will predict whether or not a play will be a QB dropback. I predict the probability of a QB dropback using the nflfastR-provided variables that collectively capture the game state at the time of the play. These variables aren't an exhaustive list of what goes into the game state, but hopefully capture most of the information relevant to teams in making the decision to run or pass. The variables are:

  - Down (limited to 1,2,3)
  - Yards for first down
  - Yard line
  - Score Differential
  - Quarter
  - Time remaining in half
  - Number of timeouts for the offense and defense
  
Note that a QB dropback is not the same as saying a pass occurred. QB dropbacks are plays where the offense intended to pass, even if they did not end up in an attempted pass (sacks, scrambles, etc...).

We'll use an xgboost model because we know there are non-linearities in the relationship between independent variables and dependent variable as well as some complex interactions between the variables. I can't say anything about xgboost that hasn't been said better in a million other data science posts so I'll just say that I, like so many others, have found xgboost extremely useful for a variety of machine learning projects.

## Tidying my xgboost

First I'll include everything to get the data set up. Note that I'm loading a few pre-built models. The code needed to build all of these objects is included but since each takes a long time to generate I'm just going to use saved versions.

```{r}
library(rstan)
library(lme4)
library(tidyverse)
library(vip)
library(tidymodels)
library(workflows)
library(dials)
library(tune)
library(DT)
library(arm)
library(tidybayes)
library(ggrepel)
set.seed(1234)
seasons <- 2016:2019
dat <- purrr::map_df(seasons, function(x) {
  readRDS(
    url(
      glue::glue("https://raw.githubusercontent.com/guga31bb/nflfastR-data/master/data/play_by_play_{x}.rds")
    )
  )
})
post16 <- filter(dat, 
                     season_type == 'REG' & 
                     down %in% c(1,2,3) &
                     !is.na(qb_dropback) &
                     !is.na(score_differential)) %>%
  mutate(qb_dropback = factor(qb_dropback),
         off_to = if_else(posteam_type == 'away', away_timeouts_remaining, home_timeouts_remaining),
         def_to = if_else(posteam_type == 'away', home_timeouts_remaining, away_timeouts_remaining)) %>%
  dplyr::select(qb_dropback, down, ydstogo, yardline_100, score_differential, qtr, half_seconds_remaining, off_to, def_to)
xgb_res <- readRDS('objects/xgb-grid-search.RDS') ## Loading hyperparameter grid results
final_mod <- readRDS('objects/final-mod-test-dat.RDS') ##Loading xgboost model
final_qb_mod <- readRDS('objects/final-full-xgb.RDS') ##loading xgboost model
fit_no_epa <- readRDS('objects/no_epa_model.RDS') ##loading stan model
samps_no_epa <- rstan::extract(fit_no_epa, pars = 'mu')$mu ##Extract mu estimates
quantile_025_no_epa <- apply(samps_no_epa, 2, quantile, .025) ##Calculate 2.5th percentile of mu estimates
quantile_975_no_epa <- apply(samps_no_epa, 2, quantile, .975) ##Extract 97.5th percentile of mu estimates
mean_no_epa <- apply(samps_no_epa, 2, mean) ##extract mean estimates
teams <- dat %>%
  filter(!is.na(posteam)) %>%
  dplyr::select(posteam, season, qb_dropback) %>%
  mutate(team_string = str_c(posteam, '-', season),
         team_idx = as.numeric(factor(team_string))) %>%
  group_by(posteam, season) %>%
  summarise(team_idx = max(team_idx),
            dropback_pct = mean(qb_dropback)) %>%
  ungroup()
teams$q_025_no_epa <- quantile_025_no_epa
teams$q_975_no_epa <- quantile_975_no_epa
teams$mean_no_epa <- mean_no_epa
teams$display_name <- factor(str_c(teams$posteam, ' - ', teams$season))
teams$display_name <- fct_reorder(teams$display_name, teams$mean_no_epa)
teams <- teams %>%
  group_by(season) %>%
  mutate(qb_dropback_rank = rank(desc(dropback_pct)),
         qb_dropback_est_rank = rank(desc(mean_no_epa)))
```

### Prepping the Data
The first step is going to be to split the data into train and test which we can do with the <code>initial_split</code> function. By default this function will use 75% of the data for training and the remaining 25% for testing. We'll look at 2016-2019, which leaves ~100k observations for training and ~35k observations for testing.

```{r}
dat_split <- initial_split(post16)
dat_train <- training(dat_split)
dat_test <- testing(dat_split)
```

We're going be tuning our xgboost hyperparameters so we'll want to perform some cross-validation to see which hyperparameters give us the best performance. We can create cross-validation sets using <code>vfold_cv()</code>.

```{r}
qb_folds <- vfold_cv(dat_train)
```


### Prepping the Model
Next we'll define a recipe using the <code>recipe()</code> function from the <code>recipes</code> package. Recipes involve setting a formula that looks like what you use to train most models in R and doing any pre-processing (scaling, normalizing, imputing, etc...) that you want to do to your variables. The nice thing about the recipe formulation is that it is the same regardless of which model you'll ultimately be using so you don't need to remember how data needs to be fed into <code>glmnet</code> vs. <code>xgboost</code> vs. <code>glm</code>. xgboost doesn't require that data be regularized or normalized so we can specify our recipe as in the formula below, but if you do need to do some kind of pre-processing you can check out the dozens of packages in <code>recipes</code> that begin with <code>step_</code>.

```{r}
qb_recipe <- recipe(qb_dropback ~ down + 
                      ydstogo + 
                      yardline_100 + 
                      score_differential + 
                      qtr + 
                      half_seconds_remaining +
                      off_to +
                      def_to,
    data = dat_train)
```

Now that we have a recipe we will get our model set up. We're going to use a boosted tree model which carries with it a bunch of tuneable hyperparameters. We will fix the number of trees to keep cross-validation from getting out of hand and tell the model to stop when there has been no improvement in 100 rounds. Everything else is going to be selected based on model fit.

The <code>set_engine()</code> specifies the package that the model is coming from so if you preferred to use <code>gbm</code> instead of <code>xgboost</code> you would specify <code>set_engine("gbm")</code>.

```{r}
qb_model <- 
  boost_tree(
    mtry = tune(),
    trees = 2000, 
    min_n = tune(),
    tree_depth = tune(),
    learn_rate = tune(),
    loss_reduction = tune(),                    
    sample_size = tune(),         
    stop_iter = 100
  ) %>% 
  set_engine("xgboost") %>% 
  set_mode("classification")
```

Finally, we're going to specify a workflow which is going to gather the recipe and model we built above. This is going to make it very easy to do parameter tuning and model building without repeatedly specifying the same information.

```{r}
qb_workflow <- workflow() %>%
  add_recipe(qb_recipe) %>%
  add_model(qb_model)
```

### Parameter Tuning

Now it's time to actually do some modeling! We'll use our cross-validation folds to try a bunch of different potential hyperparameter values and return which gives us the best out of sample fit. We'll try 40 different combinations sampled from across the hyperparameter space. Note that the <code>mtry</code> and <code>sample_size</code> parameters require additional arguments. <code>mtry()</code> refers to the number of columns to be sampled at each split. This is one where you need to be careful. If the data frame you specify for <code>finizalize</code> has more variables than you actually plan on training with, you will waste your time testing mtry values that don't make any sense for your problem. The <code>sample_size</code> argument requires a number between 0 and 1 as it's the proportion of the data that you'll use in the fitting routine.

```{r}
xgb_grid <- grid_latin_hypercube(
  finalize(mtry(), dat_train),
  min_n(),
  tree_depth(),
  learn_rate(),
  loss_reduction(),
  sample_size = sample_prop(),
  size = 40
)
```

Tuning your grid is as easy as specifying a workflow, your cross-validation data, and the grid of values to be tested. <code>save_pred = TRUE</code> is going to save all of the cross-validation predictions for later evaluation. Note that this is going to take awhile. A grid of 40 took ~6 hours on my machine. I'd set this off overnight and save the results so you can reload the object without rebuilding every time.

```{r, eval = F}
  xgb_res <- tune_grid(
    qb_workflow,
    resamples = qb_folds,
    grid = xgb_grid,
    control = control_grid(save_pred = TRUE)
  )
```

Julia Silge's post has a nice plot to show the relationship between different parameter values and model performance that we'll going to use here. On the y-axis we have the AUC of the model and on the x-axis we have the value of the hyperparameter. We're looking to see if there are any obvious correlations between performance and hyperparameter value and if we might need to expand the range of tested values. It's tough to draw any sweeping conclusions though it looks like higher values of mtry and, to a certain extent, tree depth perform better. It also doesn't appear that the best values of our hyperparameters are on the edges of our plots. Were it the case that performance was clearly increasing with higher tree depth and we didn't see a point at which model performance began to decline we would want to extend the range of hyperparameters that we test to make sure that we aren't setting those values too low.

```{r, layout="l-page"}
xgb_res %>%
  collect_metrics() %>%
  filter(.metric == "roc_auc") %>%
  dplyr::select(mean, mtry:sample_size) %>%
  pivot_longer(mtry:sample_size,
               values_to = "value",
               names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(alpha = 0.8, show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "AUC") +
  theme_minimal()
```


We can extract the best-performing set of hyperparameters using the <code>select_best()</code> function and use those values to finalize our workflow.

```{r}
best_auc <- select_best(xgb_res, "roc_auc")
qb_xgb <- finalize_workflow(
  qb_workflow,
  parameters = best_auc
)
```

At this point we're ready to evaluate the performance of the model trained on our training data with our chosen hyperparameters on our test data which we can do with the <code>last_fit()</code> function. We'll need to give the function our finalized workflow as well as our split data.

```{r, eval = F}
final_mod <- last_fit(qb_xgb, dat_split)
```

### Model Evaluation
We can find out just how well the model did using <code>collect_metrics()</code>. We ended up with 69% accuracy and an AUC of .76 which seems about right given the application. If we could perfectly predict dropback probability from game state it would be very easy to be an NFL defensive coordinator! Again, Julia Silge did a great job visualizing model outputs in her post so we will basically lift her code for this ROC curve plot

```{r, layout="l-page"}
collect_metrics(final_mod)
final_mod %>%
  collect_predictions() %>%
  roc_curve(qb_dropback, .pred_0) %>%
  ggplot(aes(x = 1 - specificity, y = sensitivity)) +
  geom_line(size = 1.5, color = "midnightblue") +
  xlab('1 - Specificity') +
  ylab('Sensitivity') +
  geom_abline(
    lty = 2, alpha = 0.5,
    color = "gray50",
    size = 1.2
  ) +
  ggtitle('ROC Curve') +
  theme_minimal()
```

As a final check on our results let's look at calibration in our test data. We want our predicted dropback probabilities to be similar to the actual dropback probabilities and it looks like that's the case! There's only 14 plays in the far right dot so I'm not going to lose any sleep over it.

```{r, layout="l-page"}
final_mod %>%
  collect_predictions() %>%
  mutate(pred_rounded = round(.pred_1,1)) %>%
  group_by(pred_rounded) %>%
  summarise(mean_prediction = mean(.pred_1),
            mean_actual = mean(as.numeric(qb_dropback) - 1),
            n = n(),
            se = sd(as.numeric(qb_dropback) - 1 - .pred_1)/sqrt(n)) %>%
  ggplot(aes(x = pred_rounded, y = mean_actual)) +
  geom_abline() +
  geom_point(aes(size = n)) +
  theme_minimal() +
  xlab('Predicted Probability') +
  ylab('Actual Probability') +
  ggtitle('Calibration Plot, Test Data') +
  ylim(0,1) +
  xlim(0,1)
```

Finally, now that we've built some confidence in the model we're going to build (using <code>fit()</code>) and predict (using <code>predict()</code>) the model on all data since 2016.

```{r, eval = F}
final_qb_mod <- fit(qb_xgb, post16)
```

```{r}
post16_pred_dat <- filter(dat, season >= 2016 & 
                   season_type == 'REG' & 
                   down %in% c(1,2,3) &
                   !is.na(qb_dropback) &
                   !is.na(score_differential)) %>%
  mutate(qb_dropback = factor(qb_dropback),
         off_to = if_else(posteam_type == 'away', away_timeouts_remaining, home_timeouts_remaining),
         def_to = if_else(posteam_type == 'away', home_timeouts_remaining, away_timeouts_remaining)) %>%
  dplyr::select(qb_dropback, down, ydstogo, yardline_100, score_differential, qtr, half_seconds_remaining, off_to, def_to, epa, posteam, defteam, season)
post16_pred_dat$dropback_prob <- predict(final_qb_mod, new_data = post16_pred_dat, type = 'prob')$.pred_1
```

As a basic sanity check let's make sure the model thinks passing is more likely in situations that we would expect. Generally speaking, throwing is more likely on third down and more likely with more yards to go which is what we'd hope to see.

```{r, echo = F, layout="l-page"}
post16_pred_dat %>%
  mutate(Down = factor(down)) %>%
  filter(down > 1 & ydstogo < 15) %>%
  ggplot(aes(x = ydstogo, y = dropback_prob, colour = Down)) +
  geom_smooth() +
  ylim(0,1) +
  scale_x_continuous(breaks = seq(0,15, by = 1)) +
  scale_colour_manual(values = c('#FFC20A','#0C7BDC')) +
  ylab('Predicted Dropback Probability') +
  xlab('Yards to Go') +
  theme_minimal() +
  labs(title = 'Predicted Dropback Probability by Down and Distance')
```


## A Quick Look At Team Tendencies

In the future we'll want to build a model that builds in additional information, but for now we can build a simple model to get an idea of which teams were more or less likely to pass than we would expect based on game script alone. Going back to the equation at the top of the post, we'll fit a multilevel model where we predict the probability of a QB dropback as a function of our predicted dropback probability along with team random effects. We can interpret these effects as the degree to which teams differ from the expectation set out by the model we made above.

We'll fit the model in stan, a popular language for fitting Bayesian models and one that people find especially useful for multilevel models. The stan code and the code to build the model in R is displayed below.

```{r, eval = F}
data{
  int<lower = 0> N; //number of observations
  int<lower = 1> I; //number of team/seasons
  int<lower = 0, upper = 1> y[N]; //qb_dropback
  int<lower = 0, upper = I> ii[N]; //team/season indicator
  vector[N] phat; //fitted probability from xgboost model
}
parameters{
  vector[I] mu_raw; //team/season random effects
  real beta_phat; //effect of p_hat, should be ~ 1
  real alpha; //intercept
  real<lower = 0> sigma_mu; //standard deviation of random effects
}
transformed parameters{
  vector[I] mu = sigma_mu * mu_raw;
}
model{
  alpha ~ normal(0, .25);
  beta_phat ~ normal(1,.25);
  mu_raw ~ normal(0,1);
  sigma_mu ~ normal(0,1);
  
  y ~ bernoulli_logit(alpha + mu[ii] + beta_phat * phat);
}
```

```{r, eval = F}
stan_mod <- stan_model(file = '/stan-models/pass-prob-stan-model-no-epa.stan')
stan_dat_no_epa <- list(
  N = nrow(final_pred_dat),
  I = max(final_pred_dat$team_idx),
  y = as.numeric(final_pred_dat$qb_dropback) - 1,
  ii = final_pred_dat$team_idx,
  phat = arm::logit(final_pred_dat$dropback_prob)
)
fit_no_epa <- sampling(stan_mod, data = stan_dat_no_epa, cores = 4, chains = 4, iter = 1000)
```

Below we'll print some parameters from the model. <code>alpha</code> is the intercept, <code>beta_phat</code> is the coefficient on the predicted pass probability from our xgboost model, and <code>sigma_mu</code> is the standard deviation in team effects. We'd expect a coefficient of 1 on <code>beta_phat</code>, so I should probably go back and look at why it's coming out a little high. While there's clearly a difference between beta_phat and our expectation, it's pretty small in substantive terms. If our xgboost model was saying that the probability of a pass is .6, this model would suggest that that true probability is something like .61 for an average team. The .18 value of <code>sigma_mu</code> means that our predicted probabilities for different teams would range from about .52 on the low end and .69 on the high end for a play where an average team is at .6.

```{r}
print(fit_no_epa, pars = c('alpha','beta_phat','sigma_mu'))
```

### Team Effects

We can extract the samples from our model and use them to get our mean parameter estimates as well as the uncertainty in those estimates.

```{r, eval = F}
samps_no_epa <- rstan::extract(fit_no_epa, pars = 'mu')$mu
quantile_025_no_epa <- apply(samps_no_epa, 2, quantile, .025)
quantile_975_no_epa <- apply(samps_no_epa, 2, quantile, .975)
mean_no_epa <- apply(samps_no_epa, 2, mean)
teams <- dat %>%
  filter(season >= 2016 & !is.na(posteam)) %>%
  dplyr::select(posteam, season, qb_dropback) %>%
  mutate(team_string = str_c(posteam, '-', season),
         team_idx = as.numeric(factor(team_string))) %>%
  group_by(posteam, season) %>%
  summarise(team_idx = max(team_idx),
            dropback_pct = mean(qb_dropback)) %>%
  ungroup()
  
teams$q_025_no_epa <- quantile_025_no_epa
teams$q_975_no_epa <- quantile_975_no_epa
teams$mean_no_epa <- mean_no_epa
teams$display_name <- factor(str_c(teams$posteam, ' - ', teams$season))
teams$display_name <- fct_reorder(teams$display_name, teams$mean_no_epa)
```

The plots below show the estimated team effects. Note that the effects on the x-axis are on the log-odds scale. The 2018 Seahawks estimate of -.47 means that we would predict a Seahawks pass with probability .38 in a situation where the league-wide probability is .5. We would predict the 2018 Steelers to pass with probability .62 in that same situation.

One interesting thing is that, beyond 2018, the Seahawks haven't been that big of an outlier. They were among the pass-heavier teams in 2016-17 and only slightly below average in 2019. We also see that some teams who run the ball a lot like the Patriots, Rams, and Saints show up as being more aggressive than dropback% would lead us to believe.


#### 2016
```{r, echo = F, layout="l-page"}
ggplot(filter(teams, season == 2016), aes(y = display_name, x = mean_no_epa)) + 
  geom_point() +
  geom_linerange(aes(xmin = q_025_no_epa, xmax = q_975_no_epa), size = .5, alpha = .5) +
  theme_minimal() +
  xlim(-.7, .7) +
  labs(title = 'Estimated Team Random Effects, 2016',
       subtitle = "Mean Value With 95% Credible Intervals") +
  ylab('') +
  xlab('Estimated Team Effects')
```

#### 2017
```{r, echo = F, layout="l-page"}
ggplot(filter(teams, season == 2017), aes(y = display_name, x = mean_no_epa)) + 
  geom_point() +
  geom_linerange(aes(xmin = q_025_no_epa, xmax = q_975_no_epa), size = .5, alpha = .5) +
  theme_minimal() +
  xlim(-.7, .7) +
  labs(title = 'Estimated Team Random Effects, 2017',
       subtitle = "Mean Value With 95% Credible Intervals") +
  ylab('') +
  xlab('Estimated Team Effects')
```

#### 2018
```{r, echo = F, layout="l-page"}
ggplot(filter(teams, season == 2018), aes(y = display_name, x = mean_no_epa)) + 
  geom_point() +
  geom_linerange(aes(xmin = q_025_no_epa, xmax = q_975_no_epa), size = .5, alpha = .5) +
  theme_minimal() +
  xlim(-.7, .7) +
  labs(title = 'Estimated Team Random Effects, 2018',
       subtitle = "Mean Value With 95% Credible Intervals") +
  ylab('') +
  xlab('Estimated Team Effects')
```

#### 2019
```{r, echo = F, layout="l-page"}
ggplot(filter(teams, season == 2019), aes(y = display_name, x = mean_no_epa)) + 
  geom_point() +
  geom_linerange(aes(xmin = q_025_no_epa, xmax = q_975_no_epa), size = .5, alpha = .5) +
  theme_minimal() +
  xlim(-.7, .7) +
  labs(title = 'Estimated Team Random Effects, 2019',
       subtitle = "Mean Value With 95% Credible Intervals") +
  ylab('') +
  xlab('Estimated Team Effects')
```


The last thing I'll show is how my estimated pass-heaviness correlates with QB Dropback%. To make the plot below I converted the model estimates and the actual QB dropback% into within-season ranks. Teams above the line are pass-heavier than their unadjusted dropback% would lead us to believe. Teams below the line are run-heavier. I highlight the Patriots to come back to the point at the beginning of the post. The Patriots consistently run more than average but are among the pass-heavier teams once game script is accounted for.

```{r, message = F, layout="l-page"}
teams %>% 
  mutate(display_name = if_else(posteam %in% c('NE'), as.character(display_name), ""),
         posteam = if_else(posteam %in% c('NE'), as.character(posteam), "")) %>%
  ggplot(aes(y = qb_dropback_rank, x = qb_dropback_est_rank)) + 
  geom_text_repel(aes(label = display_name)) +
  geom_point(aes(colour = posteam, shape = posteam), size = 2) +
  ylab('Adjusted Dropback% Rank') +
  xlab('Actual Dropback% Rank') +
  geom_smooth(method = 'lm', alpha = .25) +
  scale_colour_manual(values = c('gray','blue4')) +
  theme_minimal() +
  guides(colour = F, shape = F) +
  labs(title = "Adjusted Dropback Rank vs. Actual Dropback Rank")
```

This post is inspired by a brief twitter [thread](https://twitter.com/greerreNFL/status/1343830333783822338) between [Lee Sharpe](https://twitter.com/LeeSharpeNFL) and [Robby Greer](https://twitter.com/greerreNFL) as well as Jonathan Goldberg's previous [post](https://www.opensourcefootball.com/posts/2020-08-20-adjusting-epa-for-strenght-of-opponent/) on Open Source Football that adjusts EPA/play for opponent using 10 game rolling windows. The goal of this article is to alter EPA/play by adjusting for opponent as well as to determine the best rolling average window to maximize the predictive power of future game outcomes.

```{r libraries, echo=FALSE, include=FALSE}
# Load libraries
library(tidyverse)
library(nflfastR)
# Initialize team colors
NFL_pri <- c('ARI'='#97233f',
             'ATL'='#a71930',
             'BAL'='#241773',
             'BUF'='#00338d',
             'CAR'='#0085ca',
             'CHI'='#0b162a',
             'CIN'='#000000',
             'CLE'='#fb4f14',
             'DAL'='#002244',
             'DEN'='#002244',
             'DET'='#005a8b',
             'GB'='#203731',
             'HOU'='#03202f',
             'IND'='#002c5f',
             'JAX'='#000000',
             'KC'='#e31837',
             'LAC'='#002244',
             'LA'='#003693',
             'MIA'='#008e97',
             'MIN'='#4f2683',
             'NE'='#002244',
             'NO'='#9f8958',
             'NYG'='#0b2265',
             'NYJ'='#125740',
             'OAK'='#a5acaf',
             'LV'='#a5acaf',
             'PHI'='#004953',
             'PIT'='#000000',
             'SF'='#aa0000',
             'SEA'='#002244',
             'TB'='#d50a0a',
             'TEN'='#002244',
             'WAS'='#773141')
NFL_sec <- c('pos'='#FFFFFF',
             'neg'='#000000',
             'ARI'='#000000',
             'ATL'='#000000',
             'BAL'='#000000',
             'BUF'='#c60c30',
             'CAR'='#000000',
             'CHI'='#c83803',
             'CIN'='#fb4f14',
             'CLE'='#22150c',
             'DAL'='#b0b7bc',
             'DEN'='#fb4f14',
             'DET'='#b0b7bc',
             'GB'='#ffb612',
             'HOU'='#a71930',
             'IND'='#a5acaf',
             'JAX'='#006778',
             'KC'='#ffb612',
             'LAC'='#0073cf',
             'LA'='#ffd000',
             'MIA'='#f58220',
             'MIN'='#ffc62f',
             'NE'='#c60c30',
             'NO'='#000000',
             'NYG'='#a71930',
             'NYJ'='#000000',
             'OAK'='#000000',
             'LV'='#000000',
             'PHI'='#a5acaf',
             'PIT'='#ffb612',
             'SF'='#b3995d',
             'SEA'='#69be28',
             'TB'='#34302b',
             'TEN'='#4b92db',
             'WAS'='#ffb612')
```

# Loading in the data

Let's start by first reading in play-by-play data from 1999-2020 from @nflfastR.

```{r load data, echo=TRUE, include=TRUE}
nfl_pbp <- purrr::map_df(1999:2020, function(x) {
  readr::read_csv(
    glue::glue("https://raw.githubusercontent.com/guga31bb/nflfastR-data/master/data/play_by_play_{x}.csv.gz")
  ) %>% 
    dplyr::select(-starts_with("blocked_"))
})
```

# Methodology

Just as Jonathan did in his post, we will find every team's weekly EPA/play on offense and defense. Additionally, instead of simply finding total offense and defense EPA/play, we will break it down into passing and rushing EPA/play for offense and defense.

```{r epa calc, echo=TRUE, include=TRUE}
### Get game EPA data
# Offense EPA
epa_data <- nfl_pbp %>%
  dplyr::filter(!is.na(epa), !is.na(ep), !is.na(posteam),
                play_type == "pass" | play_type == "run" | penalty == 1, qb_kneel != 1) %>%
  dplyr::group_by(game_id, season, week, posteam, home_team) %>%
  dplyr::summarise(off_dropback_pct = mean(qb_dropback == 1),
                   off_epa = mean(epa),
                   off_pass_epa = mean(epa[qb_dropback == 1]),
                   off_rush_epa = mean(epa[qb_dropback == 0]),
                   off_epa_n = sum(qb_dropback == 1 | qb_dropback == 0),
                   off_pass_epa_n = sum(qb_dropback == 1),
                   off_rush_epa_n = sum(qb_dropback == 0),
                   .groups = "drop") %>%
  # Defense EPA
  dplyr::left_join(nfl_pbp %>%
                     filter(!is.na(epa), !is.na(ep), !is.na(posteam), 
                            play_type == "pass" | play_type == "run" | penalty == 1, qb_kneel != 1) %>%
                     dplyr::group_by(game_id, season, week, defteam, away_team) %>%
                     dplyr::summarise(def_epa = mean(epa),
                                      def_dropback_pct = mean(qb_dropback == 1),
                                      def_pass_epa = mean(epa[qb_dropback == 1]),
                                      def_rush_epa = mean(epa[qb_dropback == 0]),
                                      def_epa_n = sum(qb_dropback == 1 | qb_dropback == 0),
                                      def_pass_epa_n = sum(qb_dropback == 1),
                                      def_rush_epa_n = sum(qb_dropback == 0),
                                      .groups = "drop"),
                   by = c("game_id", "posteam" = "defteam", "season", "week")) %>%
  dplyr::mutate(opponent = ifelse(posteam == home_team, away_team, home_team)) %>%
  dplyr::select(game_id, season, week, home_team, away_team, posteam, opponent, 
                off_dropback_pct, off_epa, off_pass_epa, off_rush_epa,
                off_epa_n, off_pass_epa_n, off_rush_epa_n,
                def_epa_n, def_pass_epa_n, def_rush_epa_n,
                def_dropback_pct, def_epa, def_pass_epa, def_rush_epa) %>% 
  # Not sure why, but there is one instance where the posteam = ""
  dplyr::filter(posteam != "")
```

```{r remove pbp, include=FALSE, echo=FALSE}
# Remove pbp from environment
rm(nfl_pbp)
```

We are going to build our dataset in a very similar manner to what Jonathan did in his post, with a few changes outlined below:

* Convert each EPA statistic into a lagging moving average. The lag ensures that we compare a team’s performance against their opponent’s performance ***up to that point in the season***.

* Instead of weighting each game equally during the window, we will weight EPA by the number of plays in each game of the window.

* Instead of simply converting each statistic into a moving average of the last ten games, we will convert each statistic into a moving average using a dynamic window that ranges from ten games to twenty games (for teams that play in the Super Bowl). In other words, we will use a ten game window to predict the winner of the 11th game, but for say the 15th game, we will use a 14 game window. 

* Note that for new seasons, this ten game window serves as a prior for each team in a similar manner to Football Outsiders' weighted DVOA. For example, to predict week 3, we will use a rolling average that includes 8 games from the previous year along with weeks 1 and 2. 

* We will ignore the 1999 season and only analyze the predictive power of EPA starting with the 2000 season, allowing us to use the 1999 season as a prior.

* Finally, the `pracma` package offers several types of [rolling averages](https://rdrr.io/rforge/pracma/man/movavg.html), including simple, weighted, running and exponential rolling averages. We will play around with these types of moving averages to see what maximizes predictive power.

If you want to look at all the code for building this dataset, view the source file! Here is the function to compute moving averages based on varying window sizes:

```{r weight moving avg func, echo=TRUE, include=TRUE}
# Function to get moving average of a dynamic window from 10 - 20 games
  wt_mov_avg_local <- function(var, weight, window, type, moving = T) {
    if (length(weight) == 1 & weight[1] == 1) {
      weight <- rep(1, length(var))
    }
    if (moving) {
      dplyr::case_when(
        window == 10 ~ pracma::movavg(var*weight, n = 10, type = type)/
          pracma::movavg(weight, n = 10, type = type),
        window == 11 ~ pracma::movavg(var*weight, n = 11, type = type)/
          pracma::movavg(weight, n = 11, type = type),
        window == 12 ~ pracma::movavg(var*weight, n = 12, type = type)/
          pracma::movavg(weight, n = 12, type = type),
        window == 13 ~ pracma::movavg(var*weight, n = 13, type = type)/
          pracma::movavg(weight, n = 13, type = type),
        window == 14 ~ pracma::movavg(var*weight, n = 14, type = type)/
          pracma::movavg(weight, n = 14, type = type),
        window == 15 ~ pracma::movavg(var*weight, n = 15, type = type)/
          pracma::movavg(weight, n = 15, type = type),
        window == 16 ~ pracma::movavg(var*weight, n = 16, type = type)/
          pracma::movavg(weight, n = 16, type = type),
        window == 17 ~ pracma::movavg(var*weight, n = 17, type = type)/
          pracma::movavg(weight, n = 17, type = type),
        window == 18 ~ pracma::movavg(var*weight, n = 18, type = type)/
          pracma::movavg(weight, n = 18, type = type),
        window == 19 ~ pracma::movavg(var*weight, n = 19, type = type)/
          pracma::movavg(weight, n = 19, type = type),
        window == 20 ~ pracma::movavg(var*weight, n = 20, type = type)/
          pracma::movavg(weight, n = 20, type = type)
      )
    } else {
      pracma::movavg(var*weight, n = 10, type = type)/
        pracma::movavg(weight, n = 10, type = type)
    }
  }
```

```{r functions, echo=FALSE, include=FALSE}
# Function to create the dataset
create_rolling_data <- function(epa_data, move = T, team_n = 10, pt_diff_type = "r", epa_off = "e", epa_pass_o = "e", epa_rush_o = "r", epa_def = "s", epa_pass_d = "s", epa_rush_d = "r", epa_drop = "r") {
  
  # Join back opponent off/def EPA
  epa_data <- epa_data %>%
    dplyr::group_by(season, posteam) %>% 
    dplyr::mutate(game_number = row_number()) %>% 
    dplyr::left_join(epa_data %>%
                       dplyr::group_by(season, posteam) %>% 
                       dplyr::mutate(opp_game_number = row_number()) %>% 
                       dplyr::select(-opponent) %>%
                       dplyr::rename(opp_off_epa = off_epa,
                                     opp_off_pass_epa = off_pass_epa,
                                     opp_off_rush_epa = off_rush_epa,
                                     opp_def_epa = def_epa,
                                     opp_def_pass_epa = def_pass_epa,
                                     opp_def_rush_epa = def_rush_epa,
                                     opp_off_epa_n =  off_epa_n, 
                                     opp_off_pass_epa_n = off_pass_epa_n, 
                                     opp_off_rush_epa_n = off_rush_epa_n,
                                     opp_def_epa_n =  def_epa_n, 
                                     opp_def_pass_epa_n = def_pass_epa_n, 
                                     opp_def_rush_epa_n = def_rush_epa_n,
                                     opp_off_dropback_pct = off_dropback_pct,
                                     opp_def_dropback_pct = def_dropback_pct) %>%
                       dplyr::group_by(posteam) %>%
                       dplyr::arrange(season, week) %>%
                       dplyr::mutate(
                         window = ifelse(opp_game_number <= 10, team_n, opp_game_number),
                         # Opponent off EPA
                         opp_off_epa = dplyr::lag(wt_mov_avg_local(var = opp_off_epa, weight = opp_off_epa_n, window = window, type = epa_off, moving = move)),
                         opp_off_pass_epa = dplyr::lag(wt_mov_avg_local(var = opp_off_pass_epa, weight = opp_off_pass_epa_n, window = window, type = epa_pass_o, moving = move)),
                         opp_off_rush_epa = dplyr::lag(wt_mov_avg_local(var = opp_off_rush_epa, weight = opp_off_rush_epa_n, window = window, type = epa_rush_o, moving = move)),
                         # Opponent def EPA
                         opp_def_epa = dplyr::lag(wt_mov_avg_local(var = opp_def_epa, weight = opp_def_epa_n, window = window, type = epa_def, moving = move)),
                         opp_def_pass_epa = dplyr::lag(wt_mov_avg_local(var = opp_def_pass_epa, weight = opp_def_pass_epa_n, window = window, type = epa_pass_d, moving = move)),
                         opp_def_rush_epa = dplyr::lag(wt_mov_avg_local(var = opp_def_rush_epa, weight = opp_def_rush_epa_n, window = window, type = epa_rush_d, moving = move)),
                         # Opponent defense dropbacks
                         opp_def_dropback_pct = dplyr::lag(wt_mov_avg_local(var = opp_def_dropback_pct, weight = 1, window = window, type = epa_drop, moving = move)),
                         # Opponent offense dropbacks
                         opp_off_dropback_pct = dplyr::lag(wt_mov_avg_local(var = opp_off_dropback_pct, weight = 1, window = window, type = epa_drop, moving = move))),
                     by = c("game_id", "season", "week", "home_team", "away_team", "opponent" = "posteam")) %>% 
    # Fix errors that occur for "1999_01_BAL_STL", "2000_06_BUF_MIA", "2000_03_SD_KC" games (NAs)
    dplyr::mutate(dplyr::across(c(opp_off_dropback_pct:opp_off_rush_epa, opp_def_dropback_pct:opp_def_rush_epa),
                                ~ ifelse(is.na(.) & week != 1, 0, .)))
  
  # Join in league mean of EPA by season, week to prepare for opponent adjustments
  epa_data <- epa_data %>%
    dplyr::left_join(epa_data %>%
                       dplyr::filter(posteam == home_team) %>%
                       dplyr::group_by(season, week) %>%
                       dplyr::summarise(league_mean_total = sum(off_epa*off_epa_n + def_epa*def_epa_n)/sum(off_epa_n + def_epa_n),
                                        league_mean_dropback_pct = (mean(off_dropback_pct) + mean(def_dropback_pct))/2,
                                        league_mean_pass = sum(off_pass_epa*off_pass_epa_n + def_pass_epa*def_pass_epa_n)/sum(off_pass_epa_n + def_pass_epa_n),
                                        league_mean_rush = sum(off_rush_epa*off_rush_epa_n + def_rush_epa*def_rush_epa_n)/sum(off_rush_epa_n + def_rush_epa_n),
                                        .groups = "drop") %>%
                       dplyr::ungroup() %>%
                       dplyr::group_by(season) %>%
                       dplyr::mutate(league_mean_total = dplyr::lag(cummean(league_mean_total)),
                                     league_mean_dropback_pct = dplyr::lag(cummean(league_mean_dropback_pct)),
                                     league_mean_pass = dplyr::lag(cummean(league_mean_pass)),
                                     league_mean_rush = dplyr::lag(cummean(league_mean_rush))) %>% 
                       dplyr::ungroup(),
                     by = c("season", "week")) %>% 
    dplyr::ungroup()
  
  # Adjust EPA for opponent
  epa_data <- epa_data %>%
    dplyr::mutate(
      # Total off/def adjustments
      off_adjustment_factor = ifelse(!is.na(league_mean_total), league_mean_total-opp_def_epa, 0),
      def_adjustment_factor = ifelse(!is.na(league_mean_total), league_mean_total-opp_off_epa, 0),
      adjusted_off_epa = off_epa + off_adjustment_factor,
      adjusted_def_epa = def_epa + def_adjustment_factor,
      # Dropback pct off/def adjustments
      off_dropback_adjustment_factor = ifelse(!is.na(league_mean_dropback_pct), league_mean_dropback_pct-opp_def_dropback_pct, 0),
      def_dropback_adjustment_factor = ifelse(!is.na(league_mean_dropback_pct), league_mean_dropback_pct-opp_off_dropback_pct, 0),
      adjusted_off_dropback_pct = off_dropback_pct + off_dropback_adjustment_factor,
      adjusted_def_dropback_pct = def_dropback_pct + def_dropback_adjustment_factor,
      # Pass off/def adjustments
      off_pass_adjustment_factor = ifelse(!is.na(league_mean_pass), league_mean_pass-opp_def_pass_epa, 0),
      def_pass_adjustment_factor = ifelse(!is.na(league_mean_pass), league_mean_pass-opp_off_pass_epa, 0),
      adjusted_off_pass_epa = off_pass_epa + off_pass_adjustment_factor,
      adjusted_def_pass_epa = def_pass_epa + def_pass_adjustment_factor,
      # Rush off/def adjustments
      off_rush_adjustment_factor = ifelse(!is.na(league_mean_rush), league_mean_rush-opp_def_rush_epa, 0),
      def_rush_adjustment_factor = ifelse(!is.na(league_mean_rush), league_mean_rush-opp_off_rush_epa, 0),
      adjusted_off_rush_epa = off_rush_epa + off_rush_adjustment_factor,
      adjusted_def_rush_epa = def_rush_epa + def_rush_adjustment_factor)
  
  # Group and calculate rolling average of EPA metrics
  epa_data <- epa_data %>%
    dplyr::group_by(posteam) %>%
    dplyr::arrange(season, week) %>%
    dplyr::mutate(
      window = ifelse(game_number <= 10, team_n, game_number),
      ### Current metrics
      # Total off/def epa
      off_epa_curr = wt_mov_avg_local(var = off_epa, weight = off_epa_n, window = window, type = epa_off, moving = move),
      def_epa_curr = wt_mov_avg_local(var = def_epa, weight = def_epa_n, window = window, type = epa_def, moving = move),
      adjusted_off_epa_curr = wt_mov_avg_local(var = adjusted_off_epa, weight = off_epa_n, window = window, type = epa_off, moving = move),
      adjusted_def_epa_curr = wt_mov_avg_local(var = adjusted_def_epa, weight = def_epa_n, window = window, type = epa_def, moving = move),
      # Pass off/def epa
      off_pass_epa_curr = wt_mov_avg_local(var = off_pass_epa, weight = off_pass_epa_n, window = window, type = epa_pass_o, moving = move),
      def_pass_epa_curr = wt_mov_avg_local(var = def_pass_epa, weight = def_pass_epa_n, window = window, type = epa_pass_d, moving = move),
      adjusted_off_pass_epa_curr = wt_mov_avg_local(var = adjusted_off_pass_epa, weight = off_pass_epa_n, window = window, type = epa_pass_o, moving = move),
      adjusted_def_pass_epa_curr = wt_mov_avg_local(var = adjusted_def_pass_epa, weight = def_pass_epa_n, window = window, type = epa_pass_d, moving = move),
      # Rush off/def epa
      off_rush_epa_curr = wt_mov_avg_local(var = off_rush_epa, weight = off_rush_epa_n, window = window, type = epa_rush_o, moving = move),
      def_rush_epa_curr = wt_mov_avg_local(var = def_rush_epa, weight = def_rush_epa_n, window = window, type = epa_rush_d, moving = move),
      adjusted_off_rush_epa_curr = wt_mov_avg_local(var = adjusted_off_rush_epa, weight = off_rush_epa_n, window = window, type = epa_rush_o, moving = move),
      adjusted_def_rush_epa_curr = wt_mov_avg_local(var = adjusted_def_rush_epa, weight = def_rush_epa_n, window = window, type = epa_rush_d, moving = move),
      # Dropback pct
      off_dropback_pct_curr = wt_mov_avg_local(var = off_dropback_pct, weight = 1, window = window, type = epa_drop, moving = move),
      def_dropback_pct_curr = wt_mov_avg_local(var = def_dropback_pct, weight = 1, window = window, type = epa_drop, moving = move),
      adjusted_off_dropback_pct_curr = wt_mov_avg_local(var = adjusted_off_dropback_pct, weight = 1, window = window, type = epa_drop, moving = move),
      adjusted_def_dropback_pct_curr = wt_mov_avg_local(var = adjusted_def_dropback_pct, weight = 1, window = window, type = epa_drop, moving = move),
      ### Lagged metrics
      dplyr::across(c(off_epa_curr:adjusted_def_dropback_pct_curr),
                    ~ dplyr::lag(.),
                    .names = "{.col}_{.fn}")) %>% 
    dplyr::select(-c(off_epa, def_epa, adjusted_off_epa, adjusted_def_epa,
                     off_pass_epa, def_pass_epa,
                     adjusted_off_pass_epa, adjusted_def_pass_epa,
                     off_rush_epa, def_rush_epa,
                     adjusted_off_rush_epa, adjusted_def_rush_epa,
                     off_dropback_pct, def_dropback_pct,
                     adjusted_off_dropback_pct, adjusted_def_dropback_pct)) %>% 
    dplyr::rename_with(.cols = ends_with("_1"), ~ str_remove(., "_curr_1")) %>% 
    dplyr::ungroup() %>%
    dplyr::select(game_id, season, week, posteam,
                  off_epa, def_epa, adjusted_off_epa, adjusted_def_epa,
                  off_dropback_pct, def_dropback_pct, adjusted_off_dropback_pct, adjusted_def_dropback_pct,
                  off_pass_epa, def_pass_epa, adjusted_off_pass_epa, adjusted_def_pass_epa,
                  off_rush_epa, def_rush_epa, adjusted_off_rush_epa, adjusted_def_rush_epa,
                  ends_with("_curr"))
  
  ### Get schedule and game outcomes from Lee Sharpe
  weekly_outcomes <- suppressWarnings(readr::read_csv("https://raw.githubusercontent.com/leesharpe/nfldata/master/data/games.csv", col_types = cols())) %>% 
    dplyr::filter(!is.na(result)) %>% 
    dplyr::mutate_at(dplyr::vars(home_team, away_team),
                     ~ stringr::str_replace_all(., c("JAC" = "JAX",
                                                     "STL" = "LA",
                                                     "SL" = "LA",
                                                     "ARZ" = "ARI",
                                                     "BLT" = "BAL",
                                                     "CLV" = "CLE",
                                                     "HST" = "HOU",
                                                     "SD" = "LAC",
                                                     "OAK" = "LV")))
  
  # Double games (one row per team rather than one row per game)
  weekly_outcomes <- weekly_outcomes %>% 
    dplyr::transmute(season, week, game_date = gameday, game_id,
                     home_team, away_team, home_score, away_score,
                     team = away_team,
                     opponent = home_team,
                     points_for = away_score,
                     points_against = home_score,
                     point_differential = -result) %>% 
    dplyr::bind_rows(., weekly_outcomes %>% 
                       dplyr::transmute(season, week, game_date = gameday, game_id,
                                        home_team, away_team, home_score, away_score,
                                        team = home_team,
                                        opponent = away_team,
                                        points_for = home_score,
                                        points_against = away_score,
                                        point_differential = result)) %>% 
    dplyr::mutate(win = ifelse(point_differential > 0, 1, 0),
                  winner = ifelse(point_differential > 0, team, opponent),
                  loser = ifelse(point_differential < 0, team, opponent)) %>% 
    dplyr::arrange(season, week) %>% 
    dplyr::group_by(season, team) %>% 
    dplyr::mutate(game_number = dplyr::row_number()) %>% 
    dplyr::ungroup() %>% 
    dplyr::relocate(c(game_number, team, opponent, winner, loser), .after = game_id)
  
  # Join back opponent game outcome metrics
  weekly_outcomes <- weekly_outcomes %>%
    dplyr::left_join(weekly_outcomes %>%
                       dplyr::select(game_id, season, week, game_number, team, opponent, points_for, points_against) %>%
                       dplyr::rename(opp_points_for = points_for, 
                                     opp_points_against = points_against,
                                     opp_game_number = game_number) %>%
                       dplyr::group_by(team) %>%
                       dplyr::arrange(season, week) %>%
                       dplyr::mutate(window = ifelse(opp_game_number <= 10, team_n, opp_game_number),
                                     opp_points_for = dplyr::lag(wt_mov_avg_local(var = opp_points_for, weight = 1, window = window, type = pt_diff_type, moving = move)),
                                     opp_points_against = dplyr::lag(wt_mov_avg_local(var = opp_points_against, weight = 1, window = window, type = pt_diff_type, moving = move))) %>%
                       dplyr::select(-season, -week),
                     by = c("game_id", "team" = "opponent", "opponent" = "team"))
  
  # Join league average point scoring, differentials for opponent adjustments
  weekly_outcomes <- weekly_outcomes %>% 
    dplyr::left_join(weekly_outcomes %>%
                       dplyr::filter(team == home_team) %>%
                       dplyr::group_by(season, week) %>%
                       dplyr::summarise(league_mean_pts = mean(points_for),
                                        .groups = "drop") %>%
                       dplyr::ungroup() %>%
                       dplyr::group_by(season) %>%
                       dplyr::mutate(league_mean_pts = dplyr::lag(cummean(league_mean_pts))),
                     by = c("season", "week")) %>% 
    # Adjust points for
    dplyr::mutate(off_adjustment_factor = ifelse(!is.na(league_mean_pts) & !is.na(opp_points_against), league_mean_pts-opp_points_against, 0),
                  def_adjustment_factor = ifelse(!is.na(league_mean_pts) & !is.na(opp_points_for), league_mean_pts-opp_points_for, 0),
                  adjusted_points_for = points_for + off_adjustment_factor,
                  adjusted_points_against = points_against + def_adjustment_factor,
                  adjusted_point_differential = adjusted_points_for - adjusted_points_against)
  
  # Group and calculate rolling average of point differential metrics
  weekly_outcomes <- weekly_outcomes %>%
    dplyr::group_by(team) %>%
    dplyr::arrange(season, week) %>%
    dplyr::mutate(
      window = ifelse(game_number <= 10, team_n, game_number),
      ### Current metrics
      adjusted_points_for_curr = wt_mov_avg_local(var = adjusted_points_for, weight = 1, window = window, type = pt_diff_type, moving = move),
      adjusted_points_against_curr = wt_mov_avg_local(var = adjusted_points_against, weight = 1, window = window, type = pt_diff_type, moving = move),
      point_differential_curr = wt_mov_avg_local(var = point_differential, weight = 1, window = window, type = pt_diff_type, moving = move),
      adjusted_point_differential_curr = wt_mov_avg_local(var = adjusted_point_differential, weight = 1, window = window, type = pt_diff_type, moving = move),     
      ### Lagged metrics
      across(c(adjusted_points_for_curr:adjusted_point_differential_curr),
             ~ dplyr::lag(.),
             .names = "{.col}_{.fn}")) %>%
    dplyr::select(-c(point_differential, adjusted_point_differential,
                     adjusted_points_for, adjusted_points_against)) %>% 
    dplyr::rename_with(.cols = ends_with("_1"), ~ str_remove(., "_curr_1")) %>% 
    dplyr::ungroup() %>% 
    dplyr::select(-c(league_mean_pts, off_adjustment_factor, def_adjustment_factor))
  
  ### Create Model Dataset
  model_dataset <- weekly_outcomes %>%
    # Add opponent box score statistics
    dplyr::left_join(weekly_outcomes %>%
                       dplyr::select(game_id, team, adjusted_points_for, adjusted_points_against,
                                     point_differential, adjusted_point_differential) %>%
                       dplyr::rename(opp_point_differential = point_differential, 
                                     opp_adjusted_points_for = adjusted_points_for,
                                     opp_adjusted_points_against = adjusted_points_against,
                                     opp_adjusted_point_differential = adjusted_point_differential),
                     by = c("game_id", "opponent" = "team")) %>%
    # Add EPA statistics
    dplyr::left_join(epa_data, by = c("game_id", "season", "week", "home_team" = "posteam")) %>%
    dplyr::left_join(epa_data %>%
                       dplyr::rename(
                         # Total off/def EPA
                         opp_off_epa = off_epa,
                         opp_def_epa = def_epa,
                         opp_adjusted_off_epa = adjusted_off_epa,
                         opp_adjusted_def_epa = adjusted_def_epa,
                         # Dropback off/def pct
                         opp_off_dropback_pct = off_dropback_pct,
                         opp_def_dropback_pct = def_dropback_pct,
                         opp_adjusted_off_dropback_pct = adjusted_off_dropback_pct,
                         opp_adjusted_def_dropback_pct = adjusted_def_dropback_pct,
                         # Pass off/def EPA
                         opp_off_pass_epa = off_pass_epa,
                         opp_def_pass_epa = def_pass_epa,
                         opp_adjusted_off_pass_epa = adjusted_off_pass_epa,
                         opp_adjusted_def_pass_epa = adjusted_def_pass_epa,
                         # Rush off/def EPA
                         opp_off_rush_epa = off_rush_epa,
                         opp_def_rush_epa = def_rush_epa,
                         opp_adjusted_off_rush_epa = adjusted_off_rush_epa,
                         opp_adjusted_def_rush_epa = adjusted_def_rush_epa),
                     by = c("game_id", "season", "week", "away_team" = "posteam")) %>%
    dplyr::filter(home_team == team) %>%
    # Add home margin
    dplyr::mutate(home_margin = home_score - away_score) %>%
    # Filter NAs
    dplyr::filter(!is.na(off_epa)) %>%
    # Add numeric ID
    dplyr::mutate(numeric_id = row_number()) %>% 
    dplyr::rename(gameday = game_date)
  return(model_dataset)
}
# Function to compute predictiveness
double_for_accuracy_check <- function(dataset, type) {
  # Double games (one row per team rather than one row per game)
  g1 <- dataset %>% 
    dplyr::transmute(gameday, game_id, season, week, 
                     team = away_team,
                     opponent = home_team,
                     win = ifelse(win == 1, 0, 1),
                     margin = -home_margin,
                     opp_adjusted_point_differential,
                     opp_adjusted_off_epa,
                     opp_adjusted_def_epa,
                     opp_adjusted_off_pass_epa,
                     opp_adjusted_def_pass_epa,
                     opp_adjusted_off_rush_epa,
                     opp_adjusted_def_rush_epa,
                     opp_adjusted_off_dropback_pct,
                     opp_adjusted_def_dropback_pct,
                     opp_point_differential,
                     opp_off_epa,
                     opp_def_epa,
                     opp_off_pass_epa,
                     opp_def_pass_epa,
                     opp_off_rush_epa,
                     opp_def_rush_epa,
                     opp_off_dropback_pct,
                     opp_def_dropback_pct) %>% 
    dplyr::rename_with(.cols = starts_with("opp_"), ~ stringr::str_remove(., "opp_")) %>% 
    dplyr::mutate(location = "Away")
  
  g2 <- dataset %>% 
    dplyr::transmute(gameday, game_id, season, week, 
                     team = home_team,
                     opponent = away_team,
                     win,
                     margin = home_margin,
                     adjusted_point_differential,
                     adjusted_off_epa,
                     adjusted_def_epa,
                     adjusted_off_pass_epa,
                     adjusted_def_pass_epa,
                     adjusted_off_rush_epa,
                     adjusted_def_rush_epa,
                     adjusted_off_dropback_pct,
                     adjusted_def_dropback_pct,
                     point_differential,
                     off_epa,
                     def_epa,
                     off_pass_epa,
                     def_pass_epa,
                     off_rush_epa,
                     def_rush_epa,
                     off_dropback_pct,
                     def_dropback_pct) %>% 
    dplyr::mutate(location = "Home")
  
  doubled <- dplyr::bind_rows(g1, g2) %>% 
    dplyr::arrange(game_id, gameday, season, week) %>% 
    dplyr::mutate(off_pass_rush_epa = off_dropback_pct*off_pass_epa + (1-off_dropback_pct)*off_rush_epa,
                  def_pass_rush_epa = def_dropback_pct*def_pass_epa + (1-adjusted_def_dropback_pct)*adjusted_def_rush_epa,
                  adjusted_off_pass_rush_epa = adjusted_off_dropback_pct*adjusted_off_pass_epa + (1-adjusted_off_dropback_pct)*adjusted_off_rush_epa,
                  adjusted_def_pass_rush_epa = adjusted_def_dropback_pct*adjusted_def_pass_epa + (1-adjusted_def_dropback_pct)*adjusted_def_rush_epa)
  
  results <- doubled %>% 
    dplyr::filter(season > 1999) %>% 
    tidyr::pivot_longer(cols = c(-c(gameday:margin, location)), 
                        names_to = "metric", 
                        values_to = "value") %>% 
    tidyr::nest(data = c(-metric)) %>% 
    dplyr::mutate(regression = map(data, ~ glm(win ~ value, data = ., family = "binomial")),
                  r_squared = map(regression, fmsb::NagelkerkeR2)) %>% 
    tidyr::hoist(r_squared, r.squared = "R2") %>% 
    dplyr::arrange(desc(r.squared)) %>% 
    dplyr::select(metric, r.squared) %>% 
    dplyr::mutate(moving_avg = type)
}
# Function to plot results
plot_results <- function(results) {
  results %>% 
    dplyr::mutate(name = stringr::str_to_title(stringr::str_replace_all(metric, "_", " ")),
                  name = stringr::str_remove(name, "usted"),
                  name = stringr::str_replace_all(name, "Point Differential", "Pt Diff"),
                  name = stringr::str_remove(name, " Epa"),
                  type = dplyr::case_when(
                    stringr::str_detect(metric, "pass_rush") ~ "Complex EPA",
                    stringr::str_detect(metric, "pass") ~ "Pass EPA",
                    stringr::str_detect(metric, "rush") ~ "Rush EPA",
                    stringr::str_detect(metric, "off_epa|def_epa") ~ "Total EPA",
                    stringr::str_detect(metric, "point_diff") ~ "Point Diff",
                    stringr::str_detect(metric, "dropback") ~ "Dropback")) %>%
    dplyr::mutate(type = forcats::fct_relevel(type, "Point Diff", "Total EPA", "Complex EPA", "Pass EPA", "Rush EPA"),
                  name = forcats::fct_reorder(name, r.squared),
                  moving_avg = forcats::fct_reorder(moving_avg, r.squared)) %>% 
    dplyr::filter(type != "Dropback") %>% 
    ggplot(aes(r.squared, name, fill = moving_avg)) +
    geom_col(position = position_dodge(0.9)) +
    geom_text(aes(label = round(r.squared, 4)),
              hjust = 1, size = 2.5, color = "white", fontface = "bold",
              position = position_dodge(0.9)) +
    facet_wrap( ~ type, scales = "free") +
    scale_x_continuous(expand = c(0, 0)) +
    theme_bw() +
    theme(plot.title = element_text(face = "bold", size = 28/.pt, hjust = 0),
          plot.subtitle = element_text(face = "italic", size = 24/.pt),
          strip.background = element_rect(color = "black", fill = "#C0C0C0", size = 3.5, linetype = "blank"),
          strip.text.x = element_text(face = "bold"),
          panel.grid.minor.x = element_blank(),
          panel.grid.minor.y = element_blank(),
          panel.grid.major.y = element_blank(),
          panel.border = element_blank(),
          axis.ticks = element_blank(),
          axis.text = element_text(size = 24/.pt),
          axis.title = element_text(face = "bold", size = 26/.pt),
          plot.caption = element_text(face = "italic", size = 20/.pt),
          legend.position = c(0.8, 0.2)) +
    labs(x = expression(bold("Nagelkerke pseudo"~R^2)),
         y = NULL,
         fill = NULL,
         title = "Predictive power of various EPA metrics for the outcome of an NFL game",
         subtitle = "Logistic regression to predict win or loss",
         caption = "Chart: @jacklich10 | Data: @nflfastR | Games from 2000-2020 NFL seasons")
}
```

# Analyzing predictive power

First, let's create a dataset where we use *simple* moving averages along with a *static* window of just ten games as a baseline (this is the idea in Jonathan's post) and compare it with a dataset where we use a *simple* moving averages along with a *dynamic* window that ranges from ten to twenty games.

```{r static dynamic, include=FALSE, echo=FALSE}
# Simple static window
model_dataset <- create_rolling_data(epa_data, move = F, pt_diff_type = "s", 
                                     epa_off = "s", epa_pass_o = "s", epa_rush_o = "s", 
                                     epa_def = "s", epa_pass_d = "s", epa_rush_d = "s", 
                                     epa_drop = "s")
results_simple <- double_for_accuracy_check(dataset = model_dataset, type = "Simple")
# Dynamic window
model_dataset <- create_rolling_data(epa_data, move = T, pt_diff_type = "s", 
                                     epa_off = "s", epa_pass_o = "s", epa_rush_o = "s", 
                                     epa_def = "s", epa_pass_d = "s", epa_rush_d = "s", 
                                     epa_drop = "s")
results_dynamic <- double_for_accuracy_check(dataset = model_dataset, type = "Dynamic")
results <- dplyr::bind_rows(results_simple, results_dynamic)
```

```{r plot init, echo=FALSE, layout="l-page", fig.height=5}
# Plot
plot_results(results) +
  scale_fill_brewer(palette = "Dark2", 
                      guide = guide_legend(reverse = T))
```

Awesome! It looks like using the dynamic window (which always adds the additional information from all games played during a season) increases the predictive power of EPA/play, rather than using a static window that looks only at a team's previous ten games.

Note that the "Complex" category combines pass and rush EPA/play together as follows:

$$\text{off_pass_rush_epa} = \text{off_dropback_pct}*\text{off_pass_epa} + (1-\text{off_dropback_pct})*\text{off_rush_epa}$$

In other words, it combines a team's pass and rush EPA/play into a total EPA/play by weighting them by the percentage of time a team drops back to pass. The difference between this and total EPA/play is that the complex version adjusts pass and rush EPA separately according to the strength of opponent pass and rush EPA, whereas total EPA adjusts based on opponent holistically.

What's interesting is that adjusting defensive EPA/play for opponent offenses faced actually ***decreases*** its predictive power, albeit a very small amount. This finding might provide a little support to the "defenses are simply a product of the offenses they face", as penalizing or rewarding defenses based on the quality of the offense they face might simply be adding noise. Of course, in general, defensive strength as measured through EPA is much less predictive than offensive strength. 

Now that we know that using a dynamic window for the rolling averages works better than a simple static ten game window, let's play around with different types of moving averages from the `pracma` package. We will try *weighted*, *running* and *exponential* averages compared to the *simple* moving averages from above.

```{r pracma explore, include=FALSE, echo=FALSE}
# Weighted
model_dataset <- create_rolling_data(epa_data, move = T, pt_diff_type = "w", 
                                     epa_off = "w", epa_pass_o = "w", epa_rush_o = "w", 
                                     epa_def = "w", epa_pass_d = "w", epa_rush_d = "w", 
                                     epa_drop = "w")
results_weighted <- double_for_accuracy_check(dataset = model_dataset, type = "Weighted")
# Runnning
model_dataset <- create_rolling_data(epa_data, move = T, pt_diff_type = "r", 
                                     epa_off = "r", epa_pass_o = "r", epa_rush_o = "r", 
                                     epa_def = "r", epa_pass_d = "r", epa_rush_d = "r", 
                                     epa_drop = "r")
results_running <- double_for_accuracy_check(dataset = model_dataset, type = "Running")
# Exponential
model_dataset <- create_rolling_data(epa_data, move = T, pt_diff_type = "e", 
                                     epa_off = "e", epa_pass_o = "e", epa_rush_o = "e", 
                                     epa_def = "e", epa_pass_d = "e", epa_rush_d = "e", 
                                     epa_drop = "e")
results_exp <- double_for_accuracy_check(dataset = model_dataset, type = "Exponential")
results <- dplyr::bind_rows(results_dynamic %>% 
                              dplyr::mutate(moving_avg = "Simple"), results_weighted, results_running, results_exp)
```

```{r plot pracma, echo=FALSE, layout="l-page", fig.height=5}
plot_results(results) +
  scale_fill_brewer(palette = "Dark2", 
                      guide = guide_legend(reverse = T))
```

There is a lot to take in here, so let's break it down by category of predictor:

* Point Differential: It seems clear that a running moving average of point differential increases its predictive power the most.

* Total Offense/Defense EPA: In terms of offensive EPA, an exponential moving average works best (this is primarily driven by passing offense). In terms of defensive EPA, simple or running moving averages work best and it is difficult to discern between the two.

* Offense Pass EPA: An exponential moving average best predicts offensive pass EPA.

* Defense Pass EPA: Simple and running moving averages do about equally.

* Offense/Defense Rush EPA: A running moving average outclasses the other options.

In general, weighting recent performance more heavily increases a metric's predictive strength. Let's see if we can't combine the best types of rolling average for each predictor to generate the best set of predictors for the outcome of a game. We will use a running average for point differential, rushing offense/defense, as well as for passing and total defense and an exponential moving average for offensive pass EPA and total offensive EPA.

```{r mixed, include=FALSE, echo=FALSE}
# Mixed moving averages
model_dataset <- create_rolling_data(epa_data, move = T, pt_diff_type = "r", 
                                     epa_off = "e", epa_pass_o = "e", epa_rush_o = "r", 
                                     epa_def = "r", epa_pass_d = "r", epa_rush_d = "r", 
                                     epa_drop = "r")
results_mixed <- double_for_accuracy_check(dataset = model_dataset, type = "Mixed")
results <- dplyr::bind_rows(results_dynamic %>% 
                              dplyr::mutate(moving_avg = "Simple"), 
                            results_weighted, results_running, results_exp, results_mixed)
```

```{r plot mixed, echo=FALSE, layout="l-page", fig.height=5}
plot_results(results) +
  scale_fill_brewer(palette = "Dark2", 
                      guide = guide_legend(reverse = T))
```

So mixing the types of moving averages yields some benefits and some drawbacks. We are able to achieve the maximum level of predictive power for point differential and rushing offense/defense, however passing offense/defense suffers. It appears that when adjusting passing offense for opponent, it is better to use a lagging exponential moving average of opponent defense, yet this lagging exponential moving average of defense significantly decreases the predictive power of defensive EPA. Obviously, more work can be done to play around with different combinations of moving averages, although some improvements could easily be attributed to random noise. For now, let's use the mixed dataset to explore!

# Exploration

If you follow [Ben Baldwin](https://twitter.com/benbbaldwin) on twitter or have visited his awesome website [https://rbsdm.com/](rbsdm.com), you may be familiar with his weekly team tiers scatter plot. Let's look at the differences between those team tiers (which use unadjusted, cumulative mean EPA) and team tiers using our framework:

```{r bind adj unadj, include=FALSE, echo=FALSE}
# Join unadjusted EPA/play together with moving average, adjusted version
current_epa <- dplyr::bind_rows(model_dataset %>% 
                                  dplyr::filter(season == 2020) %>% 
                                  dplyr::filter(week == max(week)) %>% 
                                  dplyr::transmute(team,
                                                   adj_off_epa = adjusted_off_epa_curr.x,
                                                   adj_def_epa = adjusted_def_epa_curr.x),
                                model_dataset %>% 
                                  dplyr::filter(season == 2020) %>% 
                                  dplyr::filter(week == max(week)) %>% 
                                  dplyr::transmute(team = opponent,
                                                   adj_off_epa = adjusted_off_epa_curr.y,
                                                   adj_def_epa = adjusted_def_epa_curr.y)) %>% 
  dplyr::left_join(epa_data %>% 
                     dplyr::filter(season == 2020) %>% 
                     dplyr::group_by(team = posteam) %>% 
                     dplyr::summarise(off_epa = sum(off_epa*off_epa_n)/sum(off_epa_n),
                                      def_epa = sum(def_epa*def_epa_n)/sum(def_epa_n)) %>% 
                     dplyr::ungroup(),
                   by = "team") %>% 
  dplyr::left_join(nflfastR::teams_colors_logos %>% 
                     dplyr::select(team = team_abbr, team_logo_espn),
                   by = "team")
```

```{r team tiers, echo=FALSE, layout="l-page", fig.height=5, preview=TRUE}
# Plot unadjusted team tiers with adjusted team tiers
current_epa %>% 
  ggplot() +
  geom_segment(aes(x = off_epa, xend = adj_off_epa,
                   y = def_epa, yend = adj_def_epa, color = team),
               lineend = "butt", linejoin = "round", size = 1.5, alpha = 0.75,
               arrow = arrow(length = unit(0.03, "npc"), type = "closed")) +
  geom_point(aes(off_epa, def_epa, color = team),
             size = 2.5) +
  ggimage::geom_image(aes(adj_off_epa, adj_def_epa, image = team_logo_espn),
                      asp = 1.618, by = "height", size = 0.08) +
  # Averages as dashed lines
  geom_vline(aes(xintercept = mean(adj_off_epa)), lty = 2, color = "black") +
  geom_hline(aes(yintercept = mean(adj_def_epa)), lty = 2, color = "black") +
  # Slopes for 'tiers'
  geom_abline(slope = -1.5, intercept = c(-0.5, -0.4, -0.3, -0.2, -0.1, 0, 0.1, 0.2, 0.3, 0.4, 0.5), alpha = .2) +
  coord_equal() +
  scale_y_reverse() +
  scale_color_manual(values = NFL_pri) +
  theme_bw() +
  theme(aspect.ratio = 9/16,
        legend.position = "none",
        plot.title = element_text(face = "bold", size = 28/.pt, hjust = 0),
        plot.subtitle = element_text(face = "italic", size = 24/.pt),
        strip.background = element_rect(color = "black", fill = "#C0C0C0", size = 3.5, linetype = "blank"),
        strip.text.x = element_text(face = "bold"),
        panel.border = element_blank(),
        axis.ticks = element_blank(),
        axis.text = element_text(size = 24/.pt),
        axis.title = element_text(face = "bold", size = 26/.pt),
        plot.caption = element_text(face = "italic", size = 20/.pt)) +
  labs(title = "2020 Predictive NFL Team Tiers through Week 16",
       subtitle = "Arrows point from unadjusted, cumulative mean EPA to adjusted and predictive EPA",
       x = "Offensive EPA",
       y = "Defensive EPA",
       caption = "Chart: @jacklich10 | Data: @nflfastR")
```

As a Jets fan, I can't help but look at the Jets ruining their quest for Trevor Lawrence as the Jags ensure the losing continues! `r emo::ji("cry")`

```{r efficiency func, include=FALSE, echo=FALSE}
# Function to display a team's efficiency over time
efficiency_over_time <- function(dataset, current_season, current_week, team_name) {
  # Double games (one row per team rather than one row per game)
  g1 <- dataset %>% 
    dplyr::transmute(gameday, game_id, season, week, 
                     team = away_team,
                     opponent = home_team,
                     adjusted_off_epa = opp_adjusted_off_epa,
                     adjusted_def_epa = opp_adjusted_def_epa) %>% 
    dplyr::mutate(location = "Away")
  
  g2 <- dataset %>% 
    dplyr::transmute(gameday, game_id, season, week, 
                     team = home_team,
                     opponent = away_team,
                     adjusted_off_epa,
                     adjusted_def_epa) %>% 
    dplyr::mutate(location = "Home")
  
  # Bind together and fill in offense/defense efficiency for bye weeks
  doubled <- dplyr::bind_rows(g1, g2) %>% 
    dplyr::arrange(game_id, gameday, season, week) %>% 
    tidyr::complete(season, week, team) %>% 
    dplyr::mutate(season = ifelse(week == 1, season - 1, season),
                  week = ifelse(week == 1, 17, week - 1)) %>% 
    dplyr::group_by(team) %>% 
    tidyr::fill(adjusted_off_epa, adjusted_def_epa, .direction = "updown") %>% 
    dplyr::group_by(season, week) %>% 
    dplyr::mutate(off_rank = rank(-adjusted_off_epa, ties.method = "random"),
                  def_rank = rank(adjusted_def_epa, ties.method = "random")) %>% 
    dplyr::ungroup() %>% 
    dplyr::left_join(nflfastR::teams_colors_logos %>%
                       select(team_abbr, team_logo_espn), 
                     by = c("team" = "team_abbr")) %>% 
    #dplyr::filter(week <= 17, is.na(gameday)) %>%
    dplyr::filter(season %in% current_season, week <= current_week) %>% 
    tidyr::pivot_longer(cols = ends_with("_rank"), names_to = "side", values_to = "rank") %>% 
    dplyr::mutate(side = ifelse(side == "off_rank", "Offensive Efficiency", "Defensive Efficiency"),
                  side = fct_relevel(side, "Offensive Efficiency", "Defensive Efficiency"))
  
  if (length(current_season) > 1) {
    season <- paste0(current_season[1], "-", current_season[length(current_season)])
  } else {
    season <- current_season
  }
  
  plot <- doubled %>% 
    ggplot(aes(week, rank, color = team)) +
    geom_line(aes(size = ifelse(team == team_name, "A", "B"), alpha = ifelse(team == team_name, 1, 0.2)), 
              show.legend = F) +
    ggimage::geom_image(aes(max(week), rank, image = ifelse(week == max(week[team == team_name]) & team == team_name, team_logo_espn, NA)),
                        asp = 1.618, by = "height", size = 0.15, inherit.aes = F) +
    facet_wrap(~ side, nrow = 1) +
    scale_x_continuous(breaks = seq(0, 17, by = 1)) +
    scale_y_reverse(breaks = seq(1, 32, by = 3)) +
    scale_color_manual(values = NFL_pri) +
    scale_size_manual(values = c(1.5, 0.75)) +
    theme_bw() +
    theme(aspect.ratio = 9/16,
          plot.title = element_text(face = "bold", size = 28/.pt, hjust = 0),
          plot.subtitle = element_text(face = "italic", size = 24/.pt),
          strip.background = element_rect(color = "black", fill = "#C0C0C0", size = 3.5, linetype = "blank"),
          strip.text.x = element_text(face = "bold"),
          panel.grid.minor.x = element_blank(),
          panel.grid.minor.y = element_blank(),
          panel.grid.major.x = element_blank(),
          panel.border = element_blank(),
          axis.ticks = element_blank(),
          axis.text = element_text(size = 24/.pt),
          axis.title = element_text(face = "bold", size = 26/.pt),
          axis.title.y = element_text(angle = 0, vjust = 0.5),
          plot.caption = element_text(face = "italic", size = 20/.pt)) +
    labs(title = paste0(season, " ", team_name, " Efficiency"),
         subtitle = "EPA/Play adjusted for opponent",
         x = "Week",
         y = "League\nRank",
         caption =  "Chart: @jacklich10 | Data: @nflfastR")
  
  if (length(current_season) > 1) {
    return(plot + facet_wrap(season ~ side))
  } else {
    return(plot + facet_wrap(~ side, nrow = 1))
  }
}
```

We can also look at a team's offensive and defensive efficiency over the course of the season using our methodology. Here's the Chiefs and some AFC competitors:

```{r afc, echo=FALSE, layout="l-page", fig.height=3}
efficiency_over_time(model_dataset, current_season = 2020, current_week = 16, team_name = "KC")
efficiency_over_time(model_dataset, current_season = 2020, current_week = 16, team_name = "BUF")
efficiency_over_time(model_dataset, current_season = 2020, current_week = 16, team_name = "BAL")
```

And here's some NFC competitors:

```{r nfc, echo=FALSE, layout="l-page", fig.height=3}
efficiency_over_time(model_dataset, current_season = 2020, current_week = 16, team_name = "GB")
efficiency_over_time(model_dataset, current_season = 2020, current_week = 16, team_name = "NO")
efficiency_over_time(model_dataset, current_season = 2020, current_week = 16, team_name = "TB")
```